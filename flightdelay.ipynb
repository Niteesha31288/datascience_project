{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "He68f-1p2nQz",
        "g_6-Hc6Z2nQ1",
        "qWptxN_G2nQ5"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1KNJo6q2nPj"
      },
      "source": [
        "# Foundations of Data Science - Group 12\n",
        "\n",
        "\n",
        "\n",
        "Flight Delays"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYnAIPaC2nPr"
      },
      "source": [
        "Let us begin by importing the required libraries into our code. We will use the `pandas` library for dataframe operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBKpu7_k2nPt"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics, preprocessing\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from imblearn.under_sampling import CondensedNearestNeighbour"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pirHiYJ2nPw"
      },
      "source": [
        "We read the dataset from the CSV file into our dataframe object coverdata, and try to get an initial feel by printing the first 5 rows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUFDBJDC2nPz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "8e7f6e91-ffd0-47df-889f-3449fb09ff39"
      },
      "source": [
        "flights_data = pd.read_csv('Flight_delay.csv')\n",
        "flights_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Date</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>ArrTime</th>\n",
              "      <th>CRSArrTime</th>\n",
              "      <th>UniqueCarrier</th>\n",
              "      <th>Airline</th>\n",
              "      <th>FlightNum</th>\n",
              "      <th>TailNum</th>\n",
              "      <th>ActualElapsedTime</th>\n",
              "      <th>CRSElapsedTime</th>\n",
              "      <th>AirTime</th>\n",
              "      <th>ArrDelay</th>\n",
              "      <th>DepDelay</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Org_Airport</th>\n",
              "      <th>Dest</th>\n",
              "      <th>Dest_Airport</th>\n",
              "      <th>Distance</th>\n",
              "      <th>TaxiIn</th>\n",
              "      <th>TaxiOut</th>\n",
              "      <th>Cancelled</th>\n",
              "      <th>CancellationCode</th>\n",
              "      <th>Diverted</th>\n",
              "      <th>CarrierDelay</th>\n",
              "      <th>WeatherDelay</th>\n",
              "      <th>NASDelay</th>\n",
              "      <th>SecurityDelay</th>\n",
              "      <th>LateAircraftDelay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>1829</td>\n",
              "      <td>1959</td>\n",
              "      <td>1925</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>3920</td>\n",
              "      <td>N464WN</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>77</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>BWI</td>\n",
              "      <td>Baltimore-Washington International Airport</td>\n",
              "      <td>515</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>1937</td>\n",
              "      <td>2037</td>\n",
              "      <td>1940</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>509</td>\n",
              "      <td>N763SW</td>\n",
              "      <td>240</td>\n",
              "      <td>250</td>\n",
              "      <td>230</td>\n",
              "      <td>57</td>\n",
              "      <td>67</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>LAS</td>\n",
              "      <td>McCarran International Airport</td>\n",
              "      <td>1591</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>1644</td>\n",
              "      <td>1845</td>\n",
              "      <td>1725</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>1333</td>\n",
              "      <td>N334SW</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>107</td>\n",
              "      <td>80</td>\n",
              "      <td>94</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>MCO</td>\n",
              "      <td>Orlando International Airport</td>\n",
              "      <td>828</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>1452</td>\n",
              "      <td>1640</td>\n",
              "      <td>1625</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>675</td>\n",
              "      <td>N286WN</td>\n",
              "      <td>228</td>\n",
              "      <td>240</td>\n",
              "      <td>213</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>PHX</td>\n",
              "      <td>Phoenix Sky Harbor International Airport</td>\n",
              "      <td>1489</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>1323</td>\n",
              "      <td>1526</td>\n",
              "      <td>1510</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>4</td>\n",
              "      <td>N674AA</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "      <td>110</td>\n",
              "      <td>16</td>\n",
              "      <td>28</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>TPA</td>\n",
              "      <td>Tampa International Airport</td>\n",
              "      <td>838</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   DayOfWeek        Date  DepTime  ...  NASDelay  SecurityDelay LateAircraftDelay\n",
              "0          4  03-01-2019     1829  ...         0              0                32\n",
              "1          4  03-01-2019     1937  ...         0              0                47\n",
              "2          4  03-01-2019     1644  ...         0              0                72\n",
              "3          4  03-01-2019     1452  ...         0              0                12\n",
              "4          4  03-01-2019     1323  ...         0              0                16\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp8TlmAM2nP1"
      },
      "source": [
        "We see that the data is in a raw format, with no normalization or scaling done. Let's try to find the data types of the attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkyVx82AE-0q"
      },
      "source": [
        "flights_data.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sT5uKve3Fzwf"
      },
      "source": [
        "We see that most attributes have the right types. But we can do better with some dateTime attributes. Let's try to convert a few into the desired type."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZSWByZzOUse"
      },
      "source": [
        "for column in ['DayOfWeek', 'FlightNum', 'Cancelled', 'Diverted']:\n",
        "  flights_data[column] = flights_data[column].apply(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_4tJeTeHR7I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "a810a15d-c8ea-492a-8994-7f00f3f91d14"
      },
      "source": [
        "for column in ['DepTime', 'ArrTime', 'CRSArrTime']:\n",
        "  #TO CHANGE THE MISSING DIGIT ------ 958 to 0958\n",
        "  flights_data[column] = flights_data[column].map(\"{:04}\".format)\n",
        "  # ADDING COLON AFTER TWO CHARACHTER ------ 09:58\n",
        "  flights_data[column] =flights_data[column].astype(str).replace(r\"(\\d{2})(\\d+)\", r\"\\1:\\2\", regex=True)\n",
        "  #changing 24:00 to 00:00 because while changing to Standard Timestamp, we will get error if the column have 24:00 value)\n",
        "  flights_data[column] = flights_data[column].replace(to_replace ='24:', value = '00:', regex = True)\n",
        "  #Combining 'Date' column and this column\n",
        "  flights_data[column] = flights_data.Date.map(str) + \" \" + flights_data[column]\n",
        "  #Applying time stamp to dataframe combined column\n",
        "  flights_data[column] = pd.to_datetime(flights_data[column])\n",
        "flights_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Date</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>ArrTime</th>\n",
              "      <th>CRSArrTime</th>\n",
              "      <th>UniqueCarrier</th>\n",
              "      <th>Airline</th>\n",
              "      <th>FlightNum</th>\n",
              "      <th>TailNum</th>\n",
              "      <th>ActualElapsedTime</th>\n",
              "      <th>CRSElapsedTime</th>\n",
              "      <th>AirTime</th>\n",
              "      <th>ArrDelay</th>\n",
              "      <th>DepDelay</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Org_Airport</th>\n",
              "      <th>Dest</th>\n",
              "      <th>Dest_Airport</th>\n",
              "      <th>Distance</th>\n",
              "      <th>TaxiIn</th>\n",
              "      <th>TaxiOut</th>\n",
              "      <th>Cancelled</th>\n",
              "      <th>CancellationCode</th>\n",
              "      <th>Diverted</th>\n",
              "      <th>CarrierDelay</th>\n",
              "      <th>WeatherDelay</th>\n",
              "      <th>NASDelay</th>\n",
              "      <th>SecurityDelay</th>\n",
              "      <th>LateAircraftDelay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 18:29:00</td>\n",
              "      <td>2019-03-01 19:59:00</td>\n",
              "      <td>2019-03-01 19:25:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>3920</td>\n",
              "      <td>N464WN</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>77</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>BWI</td>\n",
              "      <td>Baltimore-Washington International Airport</td>\n",
              "      <td>515</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 19:37:00</td>\n",
              "      <td>2019-03-01 20:37:00</td>\n",
              "      <td>2019-03-01 19:40:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>509</td>\n",
              "      <td>N763SW</td>\n",
              "      <td>240</td>\n",
              "      <td>250</td>\n",
              "      <td>230</td>\n",
              "      <td>57</td>\n",
              "      <td>67</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>LAS</td>\n",
              "      <td>McCarran International Airport</td>\n",
              "      <td>1591</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 16:44:00</td>\n",
              "      <td>2019-03-01 18:45:00</td>\n",
              "      <td>2019-03-01 17:25:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>1333</td>\n",
              "      <td>N334SW</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>107</td>\n",
              "      <td>80</td>\n",
              "      <td>94</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>MCO</td>\n",
              "      <td>Orlando International Airport</td>\n",
              "      <td>828</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 14:52:00</td>\n",
              "      <td>2019-03-01 16:40:00</td>\n",
              "      <td>2019-03-01 16:25:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>675</td>\n",
              "      <td>N286WN</td>\n",
              "      <td>228</td>\n",
              "      <td>240</td>\n",
              "      <td>213</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>PHX</td>\n",
              "      <td>Phoenix Sky Harbor International Airport</td>\n",
              "      <td>1489</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 13:23:00</td>\n",
              "      <td>2019-03-01 15:26:00</td>\n",
              "      <td>2019-03-01 15:10:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>4</td>\n",
              "      <td>N674AA</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "      <td>110</td>\n",
              "      <td>16</td>\n",
              "      <td>28</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>TPA</td>\n",
              "      <td>Tampa International Airport</td>\n",
              "      <td>838</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  DayOfWeek        Date  ... SecurityDelay LateAircraftDelay\n",
              "0         4  03-01-2019  ...             0                32\n",
              "1         4  03-01-2019  ...             0                47\n",
              "2         4  03-01-2019  ...             0                72\n",
              "3         4  03-01-2019  ...             0                12\n",
              "4         4  03-01-2019  ...             0                16\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLsglnS02nP3"
      },
      "source": [
        "We will now find the range of each column to see if normalization to a similar scale is necessary. As expected, we will check only continuous variable as categorical variables do not require normalization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88AaHlI1N9T5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dddd20ae-e286-436e-c918-f1d10af87923"
      },
      "source": [
        "#Name of the columns having numeric values\n",
        "numeric=flights_data.select_dtypes(include=np.number).columns.tolist()\n",
        "print(numeric)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Distance', 'TaxiIn', 'TaxiOut', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j4h9p-b2nP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2433ffe-6a55-420e-c7df-3524e9acc322"
      },
      "source": [
        "for column in numeric:\n",
        "    print(\"{:40} Min:{:6} \\tMax:{:6}\".format(column, flights_data[column].min(), flights_data[column].max()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ActualElapsedTime                        Min:    15 \tMax:   727\n",
            "CRSElapsedTime                           Min:   -21 \tMax:   602\n",
            "AirTime                                  Min:     0 \tMax:   609\n",
            "ArrDelay                                 Min:    15 \tMax:  1707\n",
            "DepDelay                                 Min:     6 \tMax:  1710\n",
            "Distance                                 Min:    31 \tMax:  4502\n",
            "TaxiIn                                   Min:     0 \tMax:   207\n",
            "TaxiOut                                  Min:     0 \tMax:   383\n",
            "CarrierDelay                             Min:     0 \tMax:  1707\n",
            "WeatherDelay                             Min:     0 \tMax:  1148\n",
            "NASDelay                                 Min:     0 \tMax:  1357\n",
            "SecurityDelay                            Min:     0 \tMax:   392\n",
            "LateAircraftDelay                        Min:     0 \tMax:  1254\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2cT-aJ82nQH"
      },
      "source": [
        "There isn't a very good reason we need to normalize, but we will go ahead with normalization for now, just for comparison. We will make use of the `apply` function to normalize these columns between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W7mk1K62nQI"
      },
      "source": [
        "cols_to_norm = numeric\n",
        "normalized_flights_data[cols_to_norm] = flights_data[cols_to_norm].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
        "normalized_flights_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDuwVqeqQRvY"
      },
      "source": [
        "flights_data.to_csv('Normalized Flight data.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1srpnC1J2nQJ"
      },
      "source": [
        "As we see here, all the continuous variables have been normalized to a value between 0 and 1. Now let's try to perform some rudimentary analysis to see how much correlation exists in between the attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhRMKF272nQP"
      },
      "source": [
        "corr_matrix = flights_data.corr(method = 'pearson')\n",
        "high_corr = []\n",
        "for row in numeric:\n",
        "    for column in numeric:\n",
        "        if row != column:\n",
        "            if abs(corr_matrix[row][column]) >= 0.75:\n",
        "                if [column,row] not in high_corr:\n",
        "                    high_corr.append([row,column])\n",
        "                    print(\"{} x {} : {}\".format(row,column,corr_matrix[row][column]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk19JR772nQR"
      },
      "source": [
        "### TODO:\n",
        "We see that are six pairs of attributes that have high correlation between them. I have chosen 75% as an arbitrary value for feature selection."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuY19RaX2nQV"
      },
      "source": [
        " Now, let's see if there are any columns that are constant, that is they only have one value for all the observations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCsU3rzI2nQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e952a0af-4e27-4ca7-e70a-5c51e5bc0b18"
      },
      "source": [
        "single_valued_columns = flights_data.columns[flights_data.nunique() <= 1]\n",
        "single_valued_columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Cancelled', 'CancellationCode', 'Diverted'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuesO_-62nQW"
      },
      "source": [
        "There are three columns with a constant value and thus do not have any information to contribute to our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGIru-ieU4pn"
      },
      "source": [
        "flights_data = flights_data.drop(single_valued_columns, axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpFEbn-l2nQY"
      },
      "source": [
        " Now let's learn something about the target column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SASW-C2e2nQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a760960e-8227-49d0-c577-c05488e11a6a"
      },
      "source": [
        "delay_columns = [\"CarrierDelay\", \"WeatherDelay\", \"NASDelay\", \"SecurityDelay\", \"LateAircraftDelay\"]\n",
        "flights_data[\"Delayed\"] = flights_data[delay_columns].sum(axis=1)\n",
        "flights_data[\"Delayed\"] = [1 if (i > 0) else 0 for i in flights_data[\"Delayed\"]]\n",
        "flights_data[\"Delayed\"] = flights_data[\"Delayed\"].astype('category')\n",
        "len(flights_data[\"Delayed\"].unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkDkm1GV2nQZ"
      },
      "source": [
        "There are 2 unique target classes, as expected. Let's now have a look at how the observations are distributed in between classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcLZss982nQa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2354f7c6-9a17-4607-f2fd-efb5e5a5345f"
      },
      "source": [
        "flights_data['Delayed'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    484551\n",
              "Name: Delayed, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIb8iXBh2nQa"
      },
      "source": [
        "There seems to be a lot of class imbalance present, as the most frequent target class has more than 100000 times the observations of the least frequent target class. It is very difficult for us to proceed with this distribution, we can try some sampling methods, but there is not enough data to guarantee good results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKa1BI0Hi5kT"
      },
      "source": [
        "flights_data = flights_data.drop(['Delayed'], axis = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiqzz6ozjKxc"
      },
      "source": [
        "Initially we'll just try to do multiclass classification, before we step into prediction. So, I am replacing the values of the five delay columns with one column that shows which type of delay happened."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eey3RRprjrJE"
      },
      "source": [
        "target_column = []\n",
        "for index, data in flights_data.iterrows():\n",
        "  max_value = -1\n",
        "  target_class = None\n",
        "  for column in delay_columns:\n",
        "    if data[column] >= max_value:\n",
        "      max_value = data[column]\n",
        "      target_class = column\n",
        "  target_column.append(target_class)\n",
        "flights_data['target'] = target_column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr8hgdIHqF1o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e0e90d9-50d8-4619-f36d-20cd48e7e734"
      },
      "source": [
        "multi_class_flight_data = flights_data.drop(delay_columns, axis = 1)\n",
        "multi_class_flight_data['target'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LateAircraftDelay    230607\n",
              "CarrierDelay         144832\n",
              "NASDelay              90316\n",
              "WeatherDelay          17771\n",
              "SecurityDelay          1025\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ns3mzcnlsivw"
      },
      "source": [
        "multi_class_flight_data.to_csv('MultiClassFlight.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0BvedJ92tyYX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "ef3f7733-244a-4ce7-ae7c-b655c3240146"
      },
      "source": [
        "multi_class_flight_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>DayOfWeek</th>\n",
              "      <th>Date</th>\n",
              "      <th>DepTime</th>\n",
              "      <th>ArrTime</th>\n",
              "      <th>CRSArrTime</th>\n",
              "      <th>UniqueCarrier</th>\n",
              "      <th>Airline</th>\n",
              "      <th>FlightNum</th>\n",
              "      <th>TailNum</th>\n",
              "      <th>ActualElapsedTime</th>\n",
              "      <th>CRSElapsedTime</th>\n",
              "      <th>AirTime</th>\n",
              "      <th>ArrDelay</th>\n",
              "      <th>DepDelay</th>\n",
              "      <th>Origin</th>\n",
              "      <th>Org_Airport</th>\n",
              "      <th>Dest</th>\n",
              "      <th>Dest_Airport</th>\n",
              "      <th>Distance</th>\n",
              "      <th>TaxiIn</th>\n",
              "      <th>TaxiOut</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 18:29:00</td>\n",
              "      <td>2019-03-01 19:59:00</td>\n",
              "      <td>2019-03-01 19:25:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>3920</td>\n",
              "      <td>N464WN</td>\n",
              "      <td>90</td>\n",
              "      <td>90</td>\n",
              "      <td>77</td>\n",
              "      <td>34</td>\n",
              "      <td>34</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>BWI</td>\n",
              "      <td>Baltimore-Washington International Airport</td>\n",
              "      <td>515</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>LateAircraftDelay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 19:37:00</td>\n",
              "      <td>2019-03-01 20:37:00</td>\n",
              "      <td>2019-03-01 19:40:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>509</td>\n",
              "      <td>N763SW</td>\n",
              "      <td>240</td>\n",
              "      <td>250</td>\n",
              "      <td>230</td>\n",
              "      <td>57</td>\n",
              "      <td>67</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>LAS</td>\n",
              "      <td>McCarran International Airport</td>\n",
              "      <td>1591</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>LateAircraftDelay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 16:44:00</td>\n",
              "      <td>2019-03-01 18:45:00</td>\n",
              "      <td>2019-03-01 17:25:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>1333</td>\n",
              "      <td>N334SW</td>\n",
              "      <td>121</td>\n",
              "      <td>135</td>\n",
              "      <td>107</td>\n",
              "      <td>80</td>\n",
              "      <td>94</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>MCO</td>\n",
              "      <td>Orlando International Airport</td>\n",
              "      <td>828</td>\n",
              "      <td>6</td>\n",
              "      <td>8</td>\n",
              "      <td>LateAircraftDelay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 14:52:00</td>\n",
              "      <td>2019-03-01 16:40:00</td>\n",
              "      <td>2019-03-01 16:25:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>675</td>\n",
              "      <td>N286WN</td>\n",
              "      <td>228</td>\n",
              "      <td>240</td>\n",
              "      <td>213</td>\n",
              "      <td>15</td>\n",
              "      <td>27</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>PHX</td>\n",
              "      <td>Phoenix Sky Harbor International Airport</td>\n",
              "      <td>1489</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>LateAircraftDelay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>03-01-2019</td>\n",
              "      <td>2019-03-01 13:23:00</td>\n",
              "      <td>2019-03-01 15:26:00</td>\n",
              "      <td>2019-03-01 15:10:00</td>\n",
              "      <td>WN</td>\n",
              "      <td>Southwest Airlines Co.</td>\n",
              "      <td>4</td>\n",
              "      <td>N674AA</td>\n",
              "      <td>123</td>\n",
              "      <td>135</td>\n",
              "      <td>110</td>\n",
              "      <td>16</td>\n",
              "      <td>28</td>\n",
              "      <td>IND</td>\n",
              "      <td>Indianapolis International Airport</td>\n",
              "      <td>TPA</td>\n",
              "      <td>Tampa International Airport</td>\n",
              "      <td>838</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>LateAircraftDelay</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  DayOfWeek        Date             DepTime  ... TaxiIn TaxiOut             target\n",
              "0         4  03-01-2019 2019-03-01 18:29:00  ...      3      10  LateAircraftDelay\n",
              "1         4  03-01-2019 2019-03-01 19:37:00  ...      3       7  LateAircraftDelay\n",
              "2         4  03-01-2019 2019-03-01 16:44:00  ...      6       8  LateAircraftDelay\n",
              "3         4  03-01-2019 2019-03-01 14:52:00  ...      7       8  LateAircraftDelay\n",
              "4         4  03-01-2019 2019-03-01 13:23:00  ...      4       9  LateAircraftDelay\n",
              "\n",
              "[5 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgsCEFlorHRv"
      },
      "source": [
        "## TODO: Class Balancing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16NNl6gu9-Oa"
      },
      "source": [
        "## TODO: Encode categorical variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xT8tHOm2nQe"
      },
      "source": [
        "target = multi_class_flight_data['target']\n",
        "cols_to_drop = ['Date','DepTime','ArrTime','CRSArrTime', 'UniqueCarrier', 'Airline', 'FlightNum',\t'TailNum', 'Origin', 'Org_Airport', 'Dest', 'Dest_Airport', 'target']\n",
        "multi_class_flight_data = multi_class_flight_data.drop(cols_to_drop, axis = 1)\n",
        "\n",
        "flights_data_train, flights_data_test, target_train, target_test = train_test_split(multi_class_flight_data, target, test_size = 0.3, random_state = 11, shuffle = 1, stratify = target)\n",
        "flights_data_train, flights_data_validation, target_train, target_validation = train_test_split(flights_data_train, target_train, test_size = 0.28, shuffle = 1, stratify = target_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PzwoT_wu37Z"
      },
      "source": [
        "multi_class_flight_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4rt0Vhp2nQe"
      },
      "source": [
        "We now have the balanced data loaded and divided into training (50%) , validation (20%) and testing data (30%). Before we begin building our models let's define a function `PerformanceMetrics` to evaluate our models.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ds7HfQS2nQe"
      },
      "source": [
        "def PerformanceMetrics(actual_values, predicted_values):\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(metrics.confusion_matrix(actual_values, predicted_values))\n",
        "    print(\"\\nAccuracy:\", metrics.accuracy_score(actual_values, predicted_values))\n",
        "    print(\"\\nClassification Metrics:\")\n",
        "    print(metrics.classification_report(actual_values, predicted_values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z7Ojl142nQf"
      },
      "source": [
        "### Multinomial Logistic Regression\n",
        "\n",
        "We begin with Multinomial Logistic Regression. Logistic Regression for Python is mainly defined for binary classes, but we can adapt it to a multiclass implementation with single parameter."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZepiIeYKVU-2",
        "outputId": "1321e349-81fa-47da-9d96-cf2c61fae613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5XYNkHd2nQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "857a5c79-f751-4869-af6c-542e8e3e8efb"
      },
      "source": [
        "#Import Logistic Regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#Create a LR Classifier\n",
        "LRmodel = LogisticRegression(multi_class = 'auto', verbose = 1)\n",
        "# Train the model using the training sets\n",
        "LRmodel.fit(flights_data_train, target_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   19.1s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=1,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQJ_JMWe2nQf"
      },
      "source": [
        "The model did not take long to build, we will now look at how it performs with the test data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5lMfjqQ2nQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "680ab2cb-8298-4335-b374-b3f509bde949"
      },
      "source": [
        "#Evaluate model training performance\n",
        "target_pred_val = LRmodel.predict(flights_data_validation)\n",
        "PerformanceMetrics(target_validation, target_pred_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[  451 26016  1914     0     6]\n",
            " [  449 41902  2848     0     0]\n",
            " [   41  7994  9666     0     1]\n",
            " [    4   177    20     0     0]\n",
            " [    8  2915   558     0     2]]\n",
            "\n",
            "Accuracy: 0.5477509160594701\n",
            "\n",
            "Classification Metrics:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.47      0.02      0.03     28387\n",
            "LateAircraftDelay       0.53      0.93      0.67     45199\n",
            "         NASDelay       0.64      0.55      0.59     17702\n",
            "    SecurityDelay       0.00      0.00      0.00       201\n",
            "     WeatherDelay       0.22      0.00      0.00      3483\n",
            "\n",
            "         accuracy                           0.55     94972\n",
            "        macro avg       0.37      0.30      0.26     94972\n",
            "     weighted avg       0.52      0.55      0.44     94972\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze5ZF9NN2nQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cad9c22a-6b42-4f0f-dc24-95fd5778910e"
      },
      "source": [
        "#Evalute model performance on Test set\n",
        "target_pred = LRmodel.predict(flights_data_test)\n",
        "PerformanceMetrics(target_test, target_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[  701 39760  2979     0    10]\n",
            " [  704 63988  4489     0     1]\n",
            " [   70 12336 14686     0     3]\n",
            " [    4   273    31     0     0]\n",
            " [   15  4469   840     0     7]]\n",
            "\n",
            "Accuracy: 0.5460836784392499\n",
            "\n",
            "Classification Metrics:\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.47      0.02      0.03     43450\n",
            "LateAircraftDelay       0.53      0.92      0.67     69182\n",
            "         NASDelay       0.64      0.54      0.59     27095\n",
            "    SecurityDelay       0.00      0.00      0.00       308\n",
            "     WeatherDelay       0.33      0.00      0.00      5331\n",
            "\n",
            "         accuracy                           0.55    145366\n",
            "        macro avg       0.39      0.30      0.26    145366\n",
            "     weighted avg       0.52      0.55      0.44    145366\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VVEqMc32nQh"
      },
      "source": [
        "LR does not seem to be a very good learner, with metrics for all classes except class 7 being very poor in most cases. This could be a symptom of the class balancing that was done, where we could have lost valuable information about the first 6 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARIKu0fJ2nQi"
      },
      "source": [
        "### Is class balancing the culprit?\n",
        "Let us take a diversion here, and see how the LR model performs on the unbalanced dataset. This dataset is still normalized and the unnecessary features have been removed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53Swv-Sr2nQj"
      },
      "source": [
        "coverdata_train, coverdata_test, target_train, target_test = train_test_split(coverdata, target, test_size = 0.3, random_state = 11, shuffle = 1, stratify = target)\n",
        "coverdata_train, coverdata_validation, target_train, target_validation = train_test_split(coverdata_train, target_train, test_size = 0.28, shuffle = 1, stratify = target_train)\n",
        "\n",
        "#Import Logistic Regression model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "#Create a LR Classifier\n",
        "LRmodel = LogisticRegression(multi_class = 'auto', verbose = 1)\n",
        "# Train the model using the training sets\n",
        "LRmodel.fit(coverdata_train, target_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Gg3jbAK2nQj"
      },
      "source": [
        "We are defining a new model so that the previous knowledge from the balanced dataset should not affect the decision making capabilities of this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlSviv0Y2nQk"
      },
      "source": [
        "#Evaluate model training performance\n",
        "target_pred_val = LRmodel.predict(coverdata_validation)\n",
        "PerformanceMetrics(target_validation, target_pred_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whKA-d3v2nQk"
      },
      "source": [
        "#Evalute model performance on Test set\n",
        "target_pred = LRmodel.predict(coverdata_test)\n",
        "PerformanceMetrics(target_test, target_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzeHxAH22nQm"
      },
      "source": [
        "Performance takes a whole new curve. It does seem that the class balancing has affected a lesser number of classes than expected. Class 1,2 and 3 performed better on with the unbalanced set (not surprising as they had the most number of samples), whereas the performance with class 7 is not as bad as expected. But the significant gains in the balanced set are with class 4,5 and 6, which were well above expectations.\n",
        "\n",
        "The overall accuracy has reduced with balancing the dataset, which might suggest the model was overfitting the unbalanced dataset. This is also reinforced by the fact that performance between the different classes have a smaller gap in between them in the balanced implementation.\n",
        "\n",
        "It seems to me that we might have balanced a little more than necessary, and we could have still retained some more samples for the underperforming classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqph8Vn82nQn"
      },
      "source": [
        "### Naive-Bayes\n",
        "\n",
        "Let's try implementing Naive-Bayes. The python package for Multinomial NB does not work with negative values. So, we will find which columns have negative values in them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15XNB2-w2nQo"
      },
      "source": [
        "(flights_data_train.iloc[:,1:8] < 0 ).any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5TT2v3A2nQp"
      },
      "source": [
        "(flights_data_validation.iloc[:,1:8] < 0 ).any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DE2qx73b2nQp"
      },
      "source": [
        "(flights_data_test.iloc[:,1:8] < 0 ).any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXaj4PiG2nQp"
      },
      "source": [
        "Initially, I had run Naive-Bayes without normalizing the data, that is why these checks were done, but now there are no negative values due to normalization, hence we can proceed without making any changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Blzsyza2nQq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93dcff01-7f29-42b8-b5d9-942b1e6747e7"
      },
      "source": [
        "#Import Multinomial Naive Bayes model\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#Create a Multimnomial Classifier\n",
        "NBmodel = MultinomialNB()\n",
        "# Train the model using the training sets\n",
        "NBmodel.fit(flights_data_train, target_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5BWWTZC2nQu"
      },
      "source": [
        "Now with the model built, let's look at performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpM3IdRH2nQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1423da28-9e4c-4c20-ea9c-ca4db1f72530"
      },
      "source": [
        "#Evaluate model training performance\n",
        "target_pred_val = NBmodel.predict(flights_data_validation)\n",
        "PerformanceMetrics(target_validation, target_pred_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 2525  2881  4100  9649  9232]\n",
            " [ 4812  5920  5645 12245 16577]\n",
            " [  552   651  5680  6098  4721]\n",
            " [   17    17    41    92    34]\n",
            " [  236   291   463   687  1806]]\n",
            "\n",
            "Accuracy: 0.16871288379732974\n",
            "\n",
            "Classification Metrics:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.31      0.09      0.14     28387\n",
            "LateAircraftDelay       0.61      0.13      0.22     45199\n",
            "         NASDelay       0.36      0.32      0.34     17702\n",
            "    SecurityDelay       0.00      0.46      0.01       201\n",
            "     WeatherDelay       0.06      0.52      0.10      3483\n",
            "\n",
            "         accuracy                           0.17     94972\n",
            "        macro avg       0.27      0.30      0.16     94972\n",
            "     weighted avg       0.45      0.17      0.21     94972\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP1SEU8_2nQv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6be1e3d-93d7-4f8f-e319-46353b324779"
      },
      "source": [
        "#Evalute model performance on Test set\n",
        "target_pred = NBmodel.predict(flights_data_test)\n",
        "PerformanceMetrics(target_test, target_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 4038  4296  6250 14900 13966]\n",
            " [ 7350  9195  8430 18608 25599]\n",
            " [  817  1032  8666  9444  7136]\n",
            " [   20    26    63   146    53]\n",
            " [  336   438   750  1007  2800]]\n",
            "\n",
            "Accuracy: 0.1709134185435384\n",
            "\n",
            "Classification Metrics:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.32      0.09      0.14     43450\n",
            "LateAircraftDelay       0.61      0.13      0.22     69182\n",
            "         NASDelay       0.36      0.32      0.34     27095\n",
            "    SecurityDelay       0.00      0.47      0.01       308\n",
            "     WeatherDelay       0.06      0.53      0.10      5331\n",
            "\n",
            "         accuracy                           0.17    145366\n",
            "        macro avg       0.27      0.31      0.16    145366\n",
            "     weighted avg       0.46      0.17      0.21    145366\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpTdat_P2nQw"
      },
      "source": [
        "This is a similar performance, if not much worse, to Logistic Regression, with the first three classes doing worse on the balanced set, and the last class (which had the lowest share of observations in the unbalanced set) having the best performance, which is more than double the lowest performance.\n",
        "\n",
        "I am not exactly sure what to conclude here, but it looks like we have overshot the perfect equilibrium between classes to achieve good performance on all classes in Logistic Regression and Naive Bayes. In order to verify this conclusion, we will have to train and test both the classification algorithms on various degrees of class balanced data, which I am ommiting for this Homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJmFXAB92nQw"
      },
      "source": [
        "It is however important to note that the overall performance of Naive-Bayes has nearly doubled from an abysmal mid-30% to 59%. This was achieved by normalizing the data to values between 0 and 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpRA2iN02nQw"
      },
      "source": [
        "### K-Nearest Neighbours"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Elpjs8012nQx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b80b98-2e8e-420d-b15c-81ba0f9014d8"
      },
      "source": [
        "#Import KNN model\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "#Create a KNN Classifier\n",
        "KNNmodel = KNeighborsClassifier(n_neighbors = 1)\n",
        "# Train the model using the training sets\n",
        "KNNmodel.fit(flights_data_train, target_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bxn0UDs2nQx"
      },
      "source": [
        "Manually running K-NN over different `n_neighbors` from 1 to 15, showed little change in accuracy, with the best performance given below at `n_neighbors = 1`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiXYQOyH2nQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7e11bfc-1cb0-449f-b945-f6fbba80ec2b"
      },
      "source": [
        "#Evaluate model training performance\n",
        "target_pred_val = KNNmodel.predict(flights_data_validation)\n",
        "PerformanceMetrics(target_validation, target_pred_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[10885 13630  2739    58  1075]\n",
            " [13432 26126  4014   103  1524]\n",
            " [ 2998  4164 10013    26   501]\n",
            " [   79    86    23     3    10]\n",
            " [ 1142  1578   514     6   243]]\n",
            "\n",
            "Accuracy: 0.4977256454533968\n",
            "\n",
            "Classification Metrics:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.38      0.38      0.38     28387\n",
            "LateAircraftDelay       0.57      0.58      0.58     45199\n",
            "         NASDelay       0.58      0.57      0.57     17702\n",
            "    SecurityDelay       0.02      0.01      0.02       201\n",
            "     WeatherDelay       0.07      0.07      0.07      3483\n",
            "\n",
            "         accuracy                           0.50     94972\n",
            "        macro avg       0.32      0.32      0.32     94972\n",
            "     weighted avg       0.50      0.50      0.50     94972\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az8e6Qqn2nQy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a75633-c76b-4429-e204-c035b23bd6a1"
      },
      "source": [
        "#Evalute model performance on Test set\n",
        "target_pred = KNNmodel.predict(flights_data_test)\n",
        "PerformanceMetrics(target_test, target_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[16402 20890  4368   106  1684]\n",
            " [20365 40111  6300   136  2270]\n",
            " [ 4563  6509 15267    32   724]\n",
            " [  121   142    36     4     5]\n",
            " [ 1737  2367   813    11   403]]\n",
            "\n",
            "Accuracy: 0.4965879228980642\n",
            "\n",
            "Classification Metrics:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.38      0.38      0.38     43450\n",
            "LateAircraftDelay       0.57      0.58      0.58     69182\n",
            "         NASDelay       0.57      0.56      0.57     27095\n",
            "    SecurityDelay       0.01      0.01      0.01       308\n",
            "     WeatherDelay       0.08      0.08      0.08      5331\n",
            "\n",
            "         accuracy                           0.50    145366\n",
            "        macro avg       0.32      0.32      0.32    145366\n",
            "     weighted avg       0.50      0.50      0.50    145366\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucwUD6PW2nQy"
      },
      "source": [
        "This is our best performance yet, but the trend between the different classes is stil the same. Comparatively lower values for classes 1,2 and 3; and relatively better performance for the other 4 classes.\n",
        "\n",
        "Another odd observation is that k-NN performs best when the `n_neighbors = 1`. It is suggestive of high correlation between pairs of sample data, but this is not a good generalization, particularly when considering our limited data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "He68f-1p2nQz"
      },
      "source": [
        "### Multinomial SVM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSNPGVg32nQz"
      },
      "source": [
        "#import Multinomial SVM\n",
        "from sklearn import svm\n",
        "#Create an SVM Classifier\n",
        "SVMmodel = svm.SVC(kernel = 'rbf', verbose = 1, decision_function_shape = 'ovr')\n",
        "# Train the model using the training sets\n",
        "SVMmodel.fit(flights_data_train, target_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbtXZ4Hr2nQz"
      },
      "source": [
        "This has been one of our slowest models yet, taking the longest time to build. This build time was much worse before we balanced the data, often taking not less than 6 minutes each time. This was expected though, since SVMs are one of most complex models to train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3avrYtw2nQz"
      },
      "source": [
        "#Evaluate model training performance\n",
        "target_pred_val = SVMmodel.predict(flights_data_validation)\n",
        "PerformanceMetrics(target_validation, target_pred_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NPlF6hJ2nQ0"
      },
      "source": [
        "#Evalute model performance on Test set\n",
        "target_pred = SVMmodel.predict(flights_data_test)\n",
        "PerformanceMetrics(target_test, target_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXcZGfe32nQ0"
      },
      "source": [
        "The trend between the classes continues, and performance is slightly better than Logistic Regression and Naive-Bayes. Before balancing the data, the overall accuracy was slightly better at 70%, as was the case for many previous models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_6-Hc6Z2nQ1"
      },
      "source": [
        "### Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GL8jBFNN2nQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89ddc870-6249-4a90-a259-750a522b6914"
      },
      "source": [
        "#Import tree\n",
        "from sklearn import tree\n",
        "#Create a Decision Tree Classifier\n",
        "DTmodel = tree.DecisionTreeClassifier(random_state = 0)\n",
        "# Train the model using the training sets\n",
        "DTmodel.fit(flights_data_train, target_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
              "                       random_state=0, splitter='best')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhkbtT272nQ2"
      },
      "source": [
        "A very quick build, and in order to ensure that randomness is not a factor in building the trees for each iteration, we have set seed at `0`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwIL8b9k2nQ3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba45489e-fb1b-443d-b0a9-79663701e937"
      },
      "source": [
        "#Evaluate model training performance\n",
        "target_pred_val = DTmodel.predict(flights_data_validation)\n",
        "PerformanceMetrics(target_validation, target_pred_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[10600 13464  2923    99  1301]\n",
            " [13858 25130  4264   116  1831]\n",
            " [ 2730  4022 10333    37   580]\n",
            " [   84    84    23     0    10]\n",
            " [ 1119  1561   528     8   267]]\n",
            "\n",
            "Accuracy: 0.48782799140799393\n",
            "\n",
            "Classification Metrics:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.37      0.37      0.37     28387\n",
            "LateAircraftDelay       0.57      0.56      0.56     45199\n",
            "         NASDelay       0.57      0.58      0.58     17702\n",
            "    SecurityDelay       0.00      0.00      0.00       201\n",
            "     WeatherDelay       0.07      0.08      0.07      3483\n",
            "\n",
            "         accuracy                           0.49     94972\n",
            "        macro avg       0.32      0.32      0.32     94972\n",
            "     weighted avg       0.49      0.49      0.49     94972\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-1S8t4G2nQ4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b85b7e0e-1712-414f-f64b-fcacde7d7aca"
      },
      "source": [
        "#Evalute model performance on Test set\n",
        "target_pred = DTmodel.predict(flights_data_test)\n",
        "PerformanceMetrics(target_test, target_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[15990 20963  4424   136  1937]\n",
            " [21333 38337  6576   183  2753]\n",
            " [ 4201  6141 15868    46   839]\n",
            " [  102   156    41     2     7]\n",
            " [ 1764  2418   785     8   356]]\n",
            "\n",
            "Accuracy: 0.4853473301872515\n",
            "\n",
            "Classification Metrics:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.37      0.37      0.37     43450\n",
            "LateAircraftDelay       0.56      0.55      0.56     69182\n",
            "         NASDelay       0.57      0.59      0.58     27095\n",
            "    SecurityDelay       0.01      0.01      0.01       308\n",
            "     WeatherDelay       0.06      0.07      0.06      5331\n",
            "\n",
            "         accuracy                           0.49    145366\n",
            "        macro avg       0.31      0.32      0.32    145366\n",
            "     weighted avg       0.49      0.49      0.49    145366\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LEcdsK5G2nQ4"
      },
      "source": [
        "Really good performance, only second to k-NN. The trend between the different classes is still apparent."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWptxN_G2nQ5"
      },
      "source": [
        "### Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgYaFwmj2nQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e6d165e-567c-4095-f6f2-da48c0c90504"
      },
      "source": [
        "#Import RF model\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "#Create a RandomForest Classifier\n",
        "RFmodel = RandomForestClassifier(verbose = 1)\n",
        "# Train the model using the training sets\n",
        "RFmodel.fit(flights_data_train, target_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:  1.2min finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=1, warm_start=False)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Aukkj192nQ5"
      },
      "source": [
        "Let us look at the `varImpplot` equivalent in python for the variables. For this, we use a module called `feature_importances_` from `RandomForestClassifier`, and plot a bar graph."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSK4gP0w2nQ6"
      },
      "source": [
        "# get importance\n",
        "importance = RFmodel.feature_importances_\n",
        "# plot feature importance\n",
        "plt.figure(figsize = (15,2))\n",
        "plt.bar([ x for x in range(len(importance))], importance, tick_label = coverdata_train.columns)\n",
        "plt.xticks(rotation = 90)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrnrcQZe2nQ6"
      },
      "source": [
        "There isn't much difference in terms of feature importance, hence we will proceed without removing existing features. Now let's evaluate this model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6hVUmVn2nQ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bb40d87-d897-41f3-c5c3-3363f632f4c2"
      },
      "source": [
        "#Evaluate model training performance\n",
        "target_pred_val = RFmodel.predict(flights_data_validation)\n",
        "PerformanceMetrics(target_validation, target_pred_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    4.3s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[ 8817 18341  1198     1    30]\n",
            " [ 7795 35728  1639     1    36]\n",
            " [ 1553  5153 10978     0    18]\n",
            " [   66   119    16     0     0]\n",
            " [  880  2243   337     0    23]]\n",
            "\n",
            "Accuracy: 0.5848671187297309\n",
            "\n",
            "Classification Metrics:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.46      0.31      0.37     28387\n",
            "LateAircraftDelay       0.58      0.79      0.67     45199\n",
            "         NASDelay       0.77      0.62      0.69     17702\n",
            "    SecurityDelay       0.00      0.00      0.00       201\n",
            "     WeatherDelay       0.21      0.01      0.01      3483\n",
            "\n",
            "         accuracy                           0.58     94972\n",
            "        macro avg       0.41      0.35      0.35     94972\n",
            "     weighted avg       0.57      0.58      0.56     94972\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tysqo1_t2nQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26edb3d5-afad-42b6-918d-722820f33987"
      },
      "source": [
        "#Evalute model performance on Test set\n",
        "target_pred = RFmodel.predict(flights_data_test)\n",
        "PerformanceMetrics(target_test, target_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done 100 out of 100 | elapsed:    6.6s finished\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[13371 28204  1828     0    47]\n",
            " [12018 54587  2530     1    46]\n",
            " [ 2495  7843 16730     0    27]\n",
            " [   92   193    21     1     1]\n",
            " [ 1310  3444   529     0    48]]\n",
            "\n",
            "Accuracy: 0.5829217286022866\n",
            "\n",
            "Classification Metrics:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     CarrierDelay       0.46      0.31      0.37     43450\n",
            "LateAircraftDelay       0.58      0.79      0.67     69182\n",
            "         NASDelay       0.77      0.62      0.69     27095\n",
            "    SecurityDelay       0.50      0.00      0.01       308\n",
            "     WeatherDelay       0.28      0.01      0.02      5331\n",
            "\n",
            "         accuracy                           0.58    145366\n",
            "        macro avg       0.52      0.35      0.35    145366\n",
            "     weighted avg       0.57      0.58      0.56    145366\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31E_mFTD2nQ8"
      },
      "source": [
        "The random forest algorithm is an ensemble extension of the `tree` model, and we can see that it is better than, not only the Decision Tree, but also all the other models we have implemented. This is the advantage of combining classifiers which we will explore deeper in the next Homework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUgrwKdt2nQ9"
      },
      "source": [
        "Before we conclude, we will estimate variance for all the models we have used until now, with the function `VarianceEstimator` defined below. This function will display the aggregate performance of different instances of the same classification algorithm across various training sizes. For each training set size, we will again run the model `number_iter` times for a different subset, for example, for a training set with size 50% of the whole data, we will run a model 20 times, each time with a random subset of size 50%. Similarly for 10%, 90% and so on.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1O_jAggZ2nQ-"
      },
      "source": [
        "def VarianceEstimator():\n",
        "\n",
        "    number_iter = 20\n",
        "\n",
        "    coverdata = pd.read_csv('BalancedCover.csv', index_col = 0)\n",
        "    target = pd.read_csv('BalancedTarget.csv', index_col = 0)\n",
        "\n",
        "    target = target['target']\n",
        "\n",
        "    coverdata_train, coverdata_test, target_train, target_test = train_test_split(coverdata, target, test_size = 0.1, random_state = 11, shuffle = 1, stratify = target)\n",
        "    models = ['LR','NB','KNN','SVM','DT']\n",
        "\n",
        "    for model_name in models:\n",
        "        modelVE(model_name, number_iter, coverdata_train, coverdata_test, target_train, target_test)\n",
        "\n",
        "\n",
        "\n",
        "def modelVE(model_name, number_iter, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    if model_name == 'LR':\n",
        "        from sklearn.linear_model import LogisticRegression\n",
        "        model = LogisticRegression(max_iter = 1000, multi_class = 'auto')\n",
        "    elif model_name == 'NB':\n",
        "        from sklearn.naive_bayes import MultinomialNB\n",
        "        model = MultinomialNB()\n",
        "    elif model_name == 'KNN':\n",
        "        from sklearn.neighbors import KNeighborsClassifier\n",
        "        model = KNeighborsClassifier(n_neighbors = 1)\n",
        "    elif model_name == 'SVM':\n",
        "        from sklearn.svm import SVC\n",
        "        model = SVC(kernel = 'rbf', probability = True, decision_function_shape = 'ovr')\n",
        "    elif model_name == 'DT':\n",
        "        from sklearn import tree\n",
        "        model = tree.DecisionTreeClassifier(random_state = 0)\n",
        "\n",
        "    print(\"\\nModel Name: \", model_name)\n",
        "\n",
        "    test_size_list = [0.1, 0.5, 0.9]\n",
        "\n",
        "    #Estimate Variance for a number of training sizes\n",
        "    for test_size in test_size_list:\n",
        "        print(\"\\nTRAINING SIZE = \", 1 - test_size)\n",
        "        print(\"\\nModel loading.\", end = \"\")\n",
        "\n",
        "        accuracy_list = []\n",
        "        auc_list = []\n",
        "        accuracy_list_val = []\n",
        "\n",
        "        #Run for number of iterations\n",
        "        for i in range(number_iter):\n",
        "            if ((i+1)%3):\n",
        "                print(\".\", end = \"\")\n",
        "            else:\n",
        "                print(\"\\b\\b\", end = \"\")\n",
        "            #Splitting data randomly into 50% for each iteration\n",
        "            X_train_i, X_val_i, y_train_i, y_val_i = train_test_split(X_train, y_train, test_size = test_size, random_state = i, shuffle = 1, stratify = y_train)\n",
        "            #Training model with this instance of data\n",
        "            model.fit(X_train_i, y_train_i)\n",
        "            #print Training accuracy\n",
        "            target_pred_val = model.predict(X_val_i)\n",
        "            accuracy_list_val.append(metrics.accuracy_score(y_val_i, target_pred_val))\n",
        "            target_pred = model.predict(X_test)\n",
        "            accuracy_list.append(metrics.accuracy_score(y_test, target_pred))\n",
        "            auc_list.append(metrics.roc_auc_score(y_test, model.predict_proba(X_test), multi_class = 'ovo'))\n",
        "        print(\"\\rAverage Training Accuracy = {}\\nVariance Estimate:\\n\\tAverage Testing Accuracy = {}\\n\\tAverage AUC Score = {}\".format(sum(accuracy_list_val)/len(accuracy_list_val), sum(accuracy_list)/len(accuracy_list), sum(auc_list)/len(auc_list)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHV5lKMT2nQ_"
      },
      "source": [
        "VarianceEstimator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX92gkEC2nRA"
      },
      "source": [
        "As expected, in all the models, performance maintains a decreasing trend as the training data decreases. And even though each instance of the estimated 300 models running is fed with a random training data, the consistency in its performance shows that we indeed have a strong learner which is not overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PH4pRdwU2nRA"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "Uptil now we have implemented many data processing methods on our data, and we have seen its effects on a multitude of classification algorithms. Even though there is significant difference between the performance of the different models, we find that the relative performance among the different target classes maintains a similar trend across all the models. We've seen that normalization immensely improved training times in some models and sometimes even the performance (in the case of Naive-Bayes). Class balancing has given us mixed results, it has reduced the gap between the relative performance among the classes, but at the same time it has led to a reduction in overall accuracy (which might not be a totally bad thing as it could be that it has prevented overfitting of the models). It is worth noting here that removing the correlated features also contributed significantly to model performance in many cases, though I have not shown it in the code above.\n",
        "\n",
        "So far our best classifiers have been k-NN, Decision Tree, SVM and Logistic Regression, in that order. We will leave out Random Forest because it is an ensemble method, which we will use in the next Homework. It is obvious that for our data, non-parametric classification algorithms work better than parametric algorithms. One possible reason could be that the underlying target function is highly complex, which the parametric models are unable to emulate with their limited capacity. And the large amount of data and attributes is not an advantage to parametric models either. This is also well reinforced by the fact that the non-parametric not only have better values, but also some of highest (in most cases greater than 80%). Thus it is safe to say that the data being too spread out and complex has lead to the performance levels that we have witnessed."
      ]
    }
  ]
}